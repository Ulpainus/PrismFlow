import os
import torch
import cv2
from PIL import Image
from tqdm import tqdm
import numpy as np
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler
from controlnet_aux import LineartAnimeDetector
import shutil
import time
import gradio as gr

# ä»æˆ‘ä»¬åˆ›å»ºçš„åº“ä¸­å¯¼å…¥CycleGANå¤„ç†å™¨
from cyclegan_lib.cyclegan_processor import CycleGANProcessor

def setup_directories(output_folder):
    """åˆ›å»ºå¹¶æ¸…ç†å·¥ä½œç›®å½•"""
    input_frames_folder = os.path.join(output_folder, "input_frames")
    output_frames_folder = os.path.join(output_folder, "output_frames")
    if os.path.exists(output_folder):
        shutil.rmtree(output_folder)
    os.makedirs(input_frames_folder, exist_ok=True)
    os.makedirs(output_frames_folder, exist_ok=True)
    return input_frames_folder, output_frames_folder

def extract_frames(video_path, output_folder):
    """å°†è§†é¢‘æ‹†åˆ†ä¸ºå¸§å›¾ç‰‡"""
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise IOError(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_count = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        cv2.imwrite(os.path.join(output_folder, f"{frame_count:05d}.png"), frame)
        frame_count += 1
    cap.release()
    return fps, frame_count

def create_video(frames_folder, output_path, fps):
    """å°†æ–‡ä»¶å¤¹ä¸­çš„å›¾ç‰‡å¸§åˆæˆä¸ºè§†é¢‘ - ä½¿ç”¨æµè§ˆå™¨å…¼å®¹çš„ç¼–ç æ ¼å¼"""
    frames = sorted([f for f in os.listdir(frames_folder) if f.endswith('.png')])
    if not frames:
        return None
    
    first_frame_path = os.path.join(frames_folder, frames[0])
    first_frame_img = cv2.imread(first_frame_path)
    height, width, _ = first_frame_img.shape

    # å°è¯•ä½¿ç”¨H.264ç¼–ç å™¨ï¼ˆæµè§ˆå™¨å…¼å®¹ï¼‰
    try:
        # æ–¹æ³•1: å°è¯•ä½¿ç”¨H.264ç¼–ç å™¨
        fourcc = cv2.VideoWriter_fourcc(*'H264')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        if not out.isOpened():
            raise Exception("H264ç¼–ç å™¨ä¸å¯ç”¨")
            
        print(f"ğŸ¬ ä½¿ç”¨H.264ç¼–ç å™¨åˆ›å»ºè§†é¢‘: {width}x{height} @ {fps}fps")
        
    except Exception as e:
        print(f"âš ï¸ H.264ç¼–ç å™¨ä¸å¯ç”¨: {e}")
        try:
            # æ–¹æ³•2: å°è¯•ä½¿ç”¨XVIDç¼–ç å™¨
            fourcc = cv2.VideoWriter_fourcc(*'XVID')
            output_path_avi = output_path.replace('.mp4', '.avi')
            out = cv2.VideoWriter(output_path_avi, fourcc, fps, (width, height))
            
            if not out.isOpened():
                raise Exception("XVIDç¼–ç å™¨ä¸å¯ç”¨")
                
            print(f"ğŸ¬ ä½¿ç”¨XVIDç¼–ç å™¨åˆ›å»ºAVIè§†é¢‘: {width}x{height} @ {fps}fps")
            
        except Exception as e2:
            print(f"âš ï¸ XVIDç¼–ç å™¨ä¹Ÿä¸å¯ç”¨: {e2}")
            # æ–¹æ³•3: å›é€€åˆ°åŸå§‹mp4vç¼–ç å™¨
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
            print(f"ğŸ¬ ä½¿ç”¨mp4vç¼–ç å™¨åˆ›å»ºè§†é¢‘: {width}x{height} @ {fps}fps")

    # å†™å…¥å¸§
    for frame_name in frames:
        frame_path = os.path.join(frames_folder, frame_name)
        img = cv2.imread(frame_path)
        if img is not None:
            out.write(img)
    
    out.release()
    
    # å¦‚æœä½¿ç”¨äº†AVIæ ¼å¼ï¼Œå°è¯•è½¬æ¢ä¸ºMP4
    if output_path.endswith('.avi') and os.path.exists(output_path_avi):
        try:
            # ä½¿ç”¨ffmpegè½¬æ¢ä¸ºMP4
            import subprocess
            cmd = [
                'ffmpeg', '-i', output_path_avi, 
                '-c:v', 'libx264', '-preset', 'fast', '-crf', '23',
                '-y', output_path
            ]
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                print(f"âœ… æˆåŠŸè½¬æ¢ä¸ºMP4: {output_path}")
                # åˆ é™¤ä¸´æ—¶AVIæ–‡ä»¶
                os.remove(output_path_avi)
            else:
                print(f"âš ï¸ ffmpegè½¬æ¢å¤±è´¥: {result.stderr}")
                # ä¿ç•™AVIæ–‡ä»¶ä½œä¸ºå¤‡é€‰
                output_path = output_path_avi
                
        except Exception as e:
            print(f"âš ï¸ ffmpegä¸å¯ç”¨: {e}")
            output_path = output_path_avi
    
    return output_path

def process_video_entrypoint(
    input_video_path,
    prompt,
    strength,
    seed,
    processing_mode, 
    progress=gr.Progress(track_tqdm=True)
):
    """
    æ¥æ”¶UIå‚æ•°å¹¶æ‰§è¡Œå®Œæ•´çš„è§†é¢‘å¤„ç†æµç¨‹ã€‚
    
    æ–°å¢å‚æ•°:
    - processing_mode (str): å¤„ç†æ¨¡å¼ï¼Œå¯é€‰å€¼ä¸º "Stable Diffusion Only", "CycleGAN Only", "CycleGAN + Stable Diffusion"
    """
    if input_video_path is None:
        raise gr.Error("è¯·å…ˆä¸Šä¼ ä¸€ä¸ªè§†é¢‘ï¼")

    # 1. å‚æ•°é…ç½®
    config = {
        "output_folder": f"outputs/debug_run_{int(time.time())}",
        "base_model_path": "models/Stable-diffusion/v1-5-pruned-emaonly.safetensors",
        "controlnet_model_path": "models/ControlNet/control_v11p_sd15_lineart.pth",
        "negative_prompt": "low quality, worst quality, blurry, text, logo, watermark, signature",
        "width": 768,
        "height": 512,
        "cfg_scale": 7.5,
        "steps": 20,
    }

    # 2. å‡†å¤‡å·¥ä½œ
    progress(0, desc="å‡†å¤‡å·¥ä½œï¼šåˆ›å»ºç›®å½•...")
    input_frames_dir, output_frames_dir = setup_directories(config["output_folder"])
    
    progress(0.05, desc="å‡†å¤‡å·¥ä½œï¼šæ‹†åˆ†è§†é¢‘å¸§...")
    fps, frame_total = extract_frames(input_video_path, input_frames_dir)
    
    # 3. æ ¹æ®æ¨¡å¼ï¼ŒæŒ‰éœ€åŠ è½½æ¨¡å‹
    device = "cuda"
    cyclegan_processor = None
    pipe = None
    preprocessor = None
    
    # åŠ è½½CycleGANæ¨¡å‹
    if "CycleGAN" in processing_mode:
        progress(0.1, desc="åŠ è½½CycleGANæ¨¡å‹...")
        cyclegan_model_name = "own_cyclegan"
        
        cyclegan_netG = 'resnet_9blocks'
        cyclegan_norm = 'instance'
        cyclegan_no_dropout = True

        cyclegan_processor = CycleGANProcessor(
            model_name=cyclegan_model_name,
            netG=cyclegan_netG,
            norm=cyclegan_norm,
            no_dropout=cyclegan_no_dropout, 
            gpu_ids='0',
            generator_suffix='_A',
            preserve_resolution=True 
        )
        
    # åŠ è½½Stable Diffusionæ¨¡å‹
    if "Stable Diffusion" in processing_mode:
        progress(0.2, desc="åŠ è½½Stable Diffusionå’ŒControlNetæ¨¡å‹...")
        controlnet = ControlNetModel.from_single_file(config["controlnet_model_path"], torch_dtype=torch.float16)
        pipe = StableDiffusionControlNetPipeline.from_single_file(
            config["base_model_path"], controlnet=controlnet, torch_dtype=torch.float16, use_safetensors=True
        ).to(device)
        pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)
        preprocessor = LineartAnimeDetector.from_pretrained("lllyasviel/Annotators").to(device)

    # 4. æ ¸å¿ƒå¤„ç†å¾ªç¯
    input_frame_files = sorted(os.listdir(input_frames_dir))
    generator = torch.Generator(device=device).manual_seed(int(seed)) if seed != -1 else None

    with torch.no_grad():
        for filename in progress.tqdm(input_frame_files, desc=f"æ­£åœ¨æŒ‰æ¨¡å¼ [{processing_mode}] å¤„ç†æ¯ä¸€å¸§"):
            frame_path = os.path.join(input_frames_dir, filename)
            init_image = Image.open(frame_path).convert("RGB")
            
            original_width, original_height = init_image.size
            
            result_image = None 

            if processing_mode == "CycleGAN Only":
                stylized_image = cyclegan_processor.process_frame(init_image)
                
                if filename == input_frame_files[0]:
                    try:
                        diag_input_path = os.path.join(config["output_folder"], "z_diagnostic_input.png")
                        diag_output_path = os.path.join(config["output_folder"], "z_diagnostic_output.png")
                        init_image.save(diag_input_path)
                        stylized_image.save(diag_output_path)
                        print(f"è¯Šæ–­å›¾åƒå·²ä¿å­˜: {diag_input_path} å’Œ {diag_output_path}")
                        print(f"è¾“å…¥å°ºå¯¸: {init_image.size}, è¾“å‡ºå°ºå¯¸: {stylized_image.size}")
                    except Exception as e:
                        print(f"ä¿å­˜è¯Šæ–­å›¾åƒæ—¶å‡ºé”™: {e}")

                result_image = stylized_image
            
            elif processing_mode == "Stable Diffusion Only":
                processed_init_image = init_image.resize((config["width"], config["height"]))
                control_image = preprocessor(processed_init_image)
                result_image = pipe(
                    prompt=prompt,
                    negative_prompt=config["negative_prompt"],
                    image=processed_init_image,
                    control_image=control_image,
                    num_inference_steps=config["steps"],
                    strength=strength,
                    guidance_scale=config["cfg_scale"],
                    generator=generator
                ).images[0]

            elif processing_mode == "CycleGAN + Stable Diffusion":
                cyclegan_output_image = cyclegan_processor.process_frame(init_image)
                processed_init_image = cyclegan_output_image.resize((config["width"], config["height"]))
                control_image = preprocessor(processed_init_image)
                result_image = pipe(
                    prompt=prompt,
                    negative_prompt=config["negative_prompt"],
                    image=processed_init_image,
                    control_image=control_image,
                    num_inference_steps=config["steps"],
                    strength=strength,
                    guidance_scale=config["cfg_scale"],
                    generator=generator
                ).images[0]
            
            if result_image:
                result_image.save(os.path.join(output_frames_dir, filename))

    # 5. è§†é¢‘åˆæˆ
    progress(0.95, desc="æ­£åœ¨åˆæˆä¸ºæœ€ç»ˆè§†é¢‘...")
    final_video_path = os.path.join(config["output_folder"], "final_video.mp4")
    create_video(output_frames_dir, final_video_path, fps)

    print(f"ä»»åŠ¡å®Œæˆï¼è¾“å‡ºè§†é¢‘å·²ä¿å­˜è‡³: {final_video_path}")
    return final_video_path

if __name__ == "__main__":
    print("è¿™æ˜¯ä¸€ä¸ªæ¨¡å—åŒ–çš„è§†é¢‘å¤„ç†è„šæœ¬ã€‚")
    print("è¯·é€šè¿‡ 'debug_ui.py' æ¥è¿è¡Œå¸¦ç•Œé¢çš„è°ƒè¯•ã€‚")
